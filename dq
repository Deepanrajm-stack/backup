# Databricks notebook source
# MAGIC %pip install openpyxl

# COMMAND ----------

# DBTITLE 1,Import Libraries
from pyspark.sql.functions import col, when, count, lit, to_date
from datetime import date
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.application import MIMEApplication
import pandas as pd
import tempfile
import os
from openpyxl import Workbook

# COMMAND ----------

# MAGIC %run /Workspace/Users/dmuniraj@amgen.com/routingiq_clone/config/routingiq_config.py

# COMMAND ----------

# Load rep_routing_alignment table and filter by latest processing_date
df_rep = spark.table(dev_rep_routing_alignment_table)
max_date_rep = df_rep.agg({"processing_date": "max"}).collect()[0][0]
df_rep = df_rep.filter(col("processing_date") == lit(max_date_rep))

# Load routingiq_json_input_data table and filter by latest processing_date
df_json = spark.table(routingiq_json_input_data_table)
max_date_json = df_json.agg({"processing_date": "max"}).collect()[0][0]
df_json = df_json.filter(col("processing_date") == lit(max_date_json))

# COMMAND ----------

# DBTITLE 1,Data Quality Checks
# DQ1: Check for duplicate Account__c
dq1_df = df_rep.groupBy("Account__c").agg(count("*").alias("record_count")) \
    .filter((col("Account__c").isNotNull()) & (col("record_count") > 1)) \
    .withColumn("DQ_Rule", lit("DQ1 - Duplicate Account__c"))

# DQ2: Missing lat/lon for Account__c
dq2_df = df_rep.filter((col("Account__c").isNotNull()) &
                       ((col("Customer_Latitude__c").isNull()) | (col("Customer_Longitude__c").isNull()))) \
    .withColumn("DQ_Rule", lit("DQ2 - Missing lat/lon for Account__c"))

# DQ3: Invalid distance/latlon for specific types
valid_types = ["Walkin", "Appointment", "Call"]
dq3_df = df_rep.filter((col("Account__c").isNotNull()) &
                       (col("Type__c").isin(valid_types)) &
                       ((col("Distance__c").isNotNull()) |
                        col("Customer_Latitude__c").isNull() |
                        col("Customer_Longitude__c").isNull())) \
    .withColumn("DQ_Rule", lit("DQ3 - Invalid distance/latlon for Walkin/Appointment/Call"))

# DQ4: Distance null for Travel with null Account__c
dq4_df = df_rep.filter((col("Account__c").isNull()) &
                       (col("Type__c") == "Travel") &
                       (col("Distance__c").isNull())) \
    .withColumn("DQ_Rule", lit("DQ4 - Distance null for Travel with null Account__c"))

# DQ5: Fields should be null when Type__c is 'Wait'
dq5_df = df_rep.filter((col("Type__c") == "Wait") &
                       (col("CustomerValuationSegement__c").isNotNull() |
                        col("Customer_ID__c").isNotNull() |
                        col("Customer_Latitude__c").isNotNull() |
                        col("Customer_Longitude__c").isNotNull() |
                        col("Customer_Order__c").isNotNull() |
                        col("Customer_Priority__c").isNotNull() |
                        col("Distance__c").isNotNull() |
                        col("Route_Points_Location__c").isNotNull())) \
    .withColumn("DQ_Rule", lit("DQ5 - Fields should be null when Type__c is 'Wait'"))

# COMMAND ----------

# DBTITLE 1,Cross-Table Data Quality Check
# DQ6: Appointment in JSON missing in rep_routing_alignment
df_json_clean = df_json.withColumn("appointment_date", to_date("appointment_date_time"))
dq6_df = df_json_clean.alias("json").join(
    df_rep.alias("rep"),
    (col("json.customer_id") == col("rep.Customer_ID__c")) &
    (col("json.appointment_date") == col("rep.Date__c")),
    how="left"
).filter(~(
    (col("json.appointment_date").isNull() & col("rep.Date__c").isNull())
) & (
    col("rep.Customer_ID__c").isNull() | col("rep.Date__c").isNull()
)).withColumn("DQ_Rule", lit("DQ6 - Appointment date missing in Rep"))

display(dq6_df)

# COMMAND ----------

# DBTITLE 1,Combine All DQ Failures
# Combine all DQ check failures
combined_failures_df = dq1_df.select("*") \
    .unionByName(dq2_df, allowMissingColumns=True) \
    .unionByName(dq3_df, allowMissingColumns=True) \
    .unionByName(dq4_df, allowMissingColumns=True) \
    .unionByName(dq5_df, allowMissingColumns=True) \
    .unionByName(dq6_df, allowMissingColumns=True)

display(combined_failures_df)

# COMMAND ----------

# DBTITLE 1,Email Notification
# Send email notification if failures found
failure_count = combined_failures_df.count()

if failure_count > 0:
    # Create summary of DQ failures
    dq_check_summary_df = combined_failures_df.groupBy("DQ_Rule").count().toPandas()
    dq_check_summary_html = dq_check_summary_df.to_html(index=False, escape=False)

    # Get sample failures for email
    sample_failures_pdf = combined_failures_df.limit(10).toPandas()
    sample_failures_html = sample_failures_pdf.to_html(index=False, escape=False)

    # Create Excel file with sample failures
    tmp_excel_path = os.path.join(tempfile.gettempdir(), "DQ_Failures_Sample.xlsx")
    try:
        with pd.ExcelWriter(tmp_excel_path, engine='openpyxl') as writer:
            sample_failures_pdf.to_excel(writer, sheet_name="SampleFailures", index=False)
    except Exception as e:
        print(f"Error creating Excel file: {e}")
        tmp_excel_path = None

    # Compose email body
    email_body = f"""
    <h3>Data Quality Check - Summary</h3>
    <p><strong>Total Failed Records:</strong> {failure_count}</p>
    <h4>DQ Check Type:</h4>
    {dq_check_summary_html}
    <h4>Sample Failed Records:</h4>
    {sample_failures_html}
    """
    
    if tmp_excel_path:
        email_body += "<p>Excel file with sample records attached.</p>"

    # Email configuration
    from_email = "dmuniraj@amgen.com"
    to_email = "dmuniraj@amgen.com"
    recipients = [to_email]

    # Create email message
    msg = MIMEMultipart()
    msg['From'] = from_email
    msg['To'] = ", ".join(recipients)
    msg['Subject'] = "Post Data Quality Check - Summary"
    msg.attach(MIMEText(email_body, 'html'))

    # Attach Excel file if created successfully
    if tmp_excel_path and os.path.exists(tmp_excel_path):
        try:
            with open(tmp_excel_path, "rb") as f:
                part = MIMEApplication(f.read(), _subtype='octet-stream')
                part.add_header("Content-Disposition", "attachment", filename="DQ_Failures_Sample.xlsx")
                msg.attach(part)
        except Exception as e:
            print(f"Error attaching Excel file: {e}")

    # Send email
    try:
        with smtplib.SMTP('mailhost-i.amgen.com') as server:
            server.sendmail(from_email, recipients, msg.as_string())
        print("DQ issues found. Notification sent successfully.")
        
        # Clean up temporary file
        if tmp_excel_path and os.path.exists(tmp_excel_path):
            os.remove(tmp_excel_path)
            
    except Exception as e:
        print(f"Failed to send email: {e}")
else:
    print("No DQ failures found. All data quality checks passed.")

# COMMAND ----------

# DBTITLE 1,Summary Report
print(f"Data Quality Check Summary:")
print(f"Processing Date (Rep): {max_date_rep}")
print(f"Processing Date (JSON): {max_date_json}")
print(f"Total Records Processed (Rep): {df_rep.count()}")
print(f"Total Records Processed (JSON): {df_json.count()}")
print(f"Total DQ Failures: {failure_count}")

if failure_count > 0:
    print("\nFailure Breakdown:")
    dq_summary = combined_failures_df.groupBy("DQ_Rule").count().collect()
    for row in dq_summary:
        print(f"  {row['DQ_Rule']}: {row['count']} failures")
